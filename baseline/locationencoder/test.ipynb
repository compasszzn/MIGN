{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m lat, lon \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(latitudes, longitudes):\n\u001b[1;32m     35\u001b[0m     lonlat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[lon, lat]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)  \u001b[39m# Longitude first, then Latitude\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     embedded_lonlat \u001b[39m=\u001b[39m sh(lonlat)  \u001b[39m# Get the embedding from Spherical Harmonics\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# Append the resulting embedding to the list\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     embeddings_for_variable\u001b[39m.\u001b[39mappend(embedded_lonlat\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m))  \u001b[39m# Remove the extra dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sh/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/insitu/baseline/locationencoder/locationencoder/pe/spherical_harmonics.py:39\u001b[0m, in \u001b[0;36mSphericalHarmonics.forward\u001b[0;34m(self, lonlat)\u001b[0m\n\u001b[1;32m     36\u001b[0m             y \u001b[39m=\u001b[39m y \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mones_like(phi)\n\u001b[1;32m     37\u001b[0m         Y\u001b[39m.\u001b[39mappend(y)\n\u001b[0;32m---> 39\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(Y,dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from locationencoder.pe import SphericalHarmonics\n",
    "\n",
    "level=0\n",
    "# Initialize the Spherical Harmonics model\n",
    "sh = SphericalHarmonics(legendre_polys=level)  # Adjust degree of Legendre polynomials if needed\n",
    "\n",
    "# Variables to iterate over, including the ones you're interested in\n",
    "variables = [\n",
    "    'accumulated_precipitation',\n",
    "    # 'air_temperature_mean',\n",
    "    'air_temperature_min',\n",
    "    'air_temperature_max',\n",
    "    # 'snow_depth',\n",
    "    'fresh_snow',\n",
    "    'wind_speed'\n",
    "]\n",
    "\n",
    "for variable in variables:\n",
    "    # Read the CSV file for the current variable\n",
    "    station_data = pd.read_csv(f\"/data/zzn/insitu/insitu_daily_st/unique_primary_station_ids_{variable}.csv\")\n",
    "    \n",
    "    # Extract latitude and longitude for each station\n",
    "    latitudes = station_data['latitude'].values\n",
    "    longitudes = station_data['longitude'].values\n",
    "    \n",
    "    # Create a list to hold embeddings for this variable\n",
    "    embeddings_for_variable = []\n",
    "    \n",
    "    # Process each station's coordinates and compute embedding\n",
    "    for lat, lon in zip(latitudes, longitudes):\n",
    "        lonlat = torch.tensor([[lon, lat]], dtype=torch.float32)  # Longitude first, then Latitude\n",
    "        embedded_lonlat = sh(lonlat)  # Get the embedding from Spherical Harmonics\n",
    "        # Append the resulting embedding to the list\n",
    "        embeddings_for_variable.append(embedded_lonlat.squeeze(0))  # Remove the extra dimension\n",
    "    # Convert the list of embeddings into a 2D tensor for this variable\n",
    "    embeddings_tensor = torch.stack(embeddings_for_variable)  # Shape: [num_stations, embedding_dim]\n",
    "    \n",
    "    # Save the embeddings for this variable to a file\n",
    "    embeddings_file = Path('/data/zzn/insitu/insitu_daily_st') / f'{variable}_embeddings_level_{level}.pt'\n",
    "    torch.save(embeddings_tensor, embeddings_file)\n",
    "    print(f\"Embeddings for {variable} saved to {embeddings_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for MAX saved to /data/zzn/insitu/Processed/air_temperature_max_embeddings.pt\n",
      "Embeddings for MIN saved to /data/zzn/insitu/Processed/air_temperature_min_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from locationencoder.pe import SphericalHarmonics\n",
    "\n",
    "level=3\n",
    "# Initialize the Spherical Harmonics model\n",
    "sh = SphericalHarmonics(legendre_polys=level)  # Adjust degree of Legendre polynomials if needed\n",
    "\n",
    "# Variables to iterate over, including the ones you're interested in\n",
    "variables = [\n",
    "    'MAX',\n",
    "    # 'air_temperature_mean',\n",
    "    'MIN',\n",
    "]\n",
    "node_mapping = {\n",
    "    'MAX':'air_temperature_max', \n",
    "    # 'air_temperature_mean', \n",
    "    'MIN':'air_temperature_min', \n",
    "}\n",
    "for variable in variables:\n",
    "    # Read the CSV file for the current variable\n",
    "    station_data = pd.read_csv(f\"/data/zzn/insitu/Processed/unique_primary_station_ids_{variable}_tune.csv\")\n",
    "    \n",
    "    # Extract latitude and longitude for each station\n",
    "    latitudes = station_data['latitude'].values\n",
    "    longitudes = station_data['longitude'].values\n",
    "    \n",
    "    # Create a list to hold embeddings for this variable\n",
    "    embeddings_for_variable = []\n",
    "    \n",
    "    # Process each station's coordinates and compute embedding\n",
    "    for lat, lon in zip(latitudes, longitudes):\n",
    "        lonlat = torch.tensor([[lon, lat]], dtype=torch.float32)  # Longitude first, then Latitude\n",
    "        embedded_lonlat = sh(lonlat)  # Get the embedding from Spherical Harmonics\n",
    "        # Append the resulting embedding to the list\n",
    "        embeddings_for_variable.append(embedded_lonlat.squeeze(0))  # Remove the extra dimension\n",
    "    # Convert the list of embeddings into a 2D tensor for this variable\n",
    "    embeddings_tensor = torch.stack(embeddings_for_variable)  # Shape: [num_stations, embedding_dim]\n",
    "    \n",
    "    # Save the embeddings for this variable to a file\n",
    "    embeddings_file = Path('/data/zzn/insitu/Processed') / f'{node_mapping[variable]}_embeddings.pt'\n",
    "    torch.save(embeddings_tensor, embeddings_file)\n",
    "    print(f\"Embeddings for {variable} saved to {embeddings_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for MAX saved to /data/zzn/insitu/nips/MAX_embeddings_4.pt\n",
      "Embeddings for WDSP saved to /data/zzn/insitu/nips/WDSP_embeddings_4.pt\n",
      "Embeddings for MIN saved to /data/zzn/insitu/nips/MIN_embeddings_4.pt\n",
      "Embeddings for SLP saved to /data/zzn/insitu/nips/SLP_embeddings_4.pt\n",
      "Embeddings for MXSPD saved to /data/zzn/insitu/nips/MXSPD_embeddings_4.pt\n",
      "Embeddings for DEWP saved to /data/zzn/insitu/nips/DEWP_embeddings_4.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from locationencoder.pe import SphericalHarmonics\n",
    "\n",
    "level=4\n",
    "# Initialize the Spherical Harmonics model\n",
    "sh = SphericalHarmonics(legendre_polys=level)  # Adjust degree of Legendre polynomials if needed\n",
    "\n",
    "# Variables to iterate over, including the ones you're interested in\n",
    "variables = [\n",
    "    'MAX',\n",
    "    'WDSP',\n",
    "    'MIN',\n",
    "    'SLP',\n",
    "    'MXSPD',\n",
    "    'DEWP'\n",
    "]\n",
    "\n",
    "for variable in variables:\n",
    "    # Read the CSV file for the current variable\n",
    "    station_data = pd.read_csv(f\"/data/zzn/insitu/nips/unique_primary_station_ids_{variable}_tune.csv\")\n",
    "    \n",
    "    # Extract latitude and longitude for each station\n",
    "    latitudes = station_data['latitude'].values\n",
    "    longitudes = station_data['longitude'].values\n",
    "    \n",
    "    # Create a list to hold embeddings for this variable\n",
    "    embeddings_for_variable = []\n",
    "    \n",
    "    # Process each station's coordinates and compute embedding\n",
    "    for lat, lon in zip(latitudes, longitudes):\n",
    "        lonlat = torch.tensor([[lon, lat]], dtype=torch.float32)  # Longitude first, then Latitude\n",
    "        embedded_lonlat = sh(lonlat)  # Get the embedding from Spherical Harmonics\n",
    "        # Append the resulting embedding to the list\n",
    "        embeddings_for_variable.append(embedded_lonlat.squeeze(0))  # Remove the extra dimension\n",
    "    # Convert the list of embeddings into a 2D tensor for this variable\n",
    "    embeddings_tensor = torch.stack(embeddings_for_variable)  # Shape: [num_stations, embedding_dim]\n",
    "    \n",
    "    # Save the embeddings for this variable to a file\n",
    "    embeddings_file = Path('/data/zzn/insitu/nips') / f'{variable}_embeddings_{level}.pt'\n",
    "    torch.save(embeddings_tensor, embeddings_file)\n",
    "    print(f\"Embeddings for {variable} saved to {embeddings_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([744, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load(\"/data/zzn/insitu/insitu_daily_st/wind_speed_embeddings_level_4.pt\")\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for 0 saved to /data/zzn/insitu/nips/0_healpix_embeddings_level_3.pt\n"
     ]
    }
   ],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from locationencoder.pe import SphericalHarmonics\n",
    "refinement_level = 0\n",
    "level = 3\n",
    "nside = 2 ** refinement_level\n",
    "n_pixels = hp.nside2npix(nside)\n",
    "theta, phi = hp.pix2ang(nside, np.arange(n_pixels))\n",
    "latitudes = 90 - np.degrees(theta)\n",
    "longitudes = np.degrees(phi) - 180\n",
    "\n",
    "# latitudes = station_data['latitude'].values\n",
    "# longitudes = station_data['longitude'].values\n",
    "sh = SphericalHarmonics(legendre_polys=level)  # Adjust degree of Legendre polynomials if needed\n",
    "# Create a list to hold embeddings for this variable\n",
    "embeddings_for_variable = []\n",
    "\n",
    "# Process each station's coordinates and compute embedding\n",
    "for lat, lon in zip(latitudes, longitudes):\n",
    "    lonlat = torch.tensor([[lon, lat]], dtype=torch.float32)  # Longitude first, then Latitude\n",
    "    embedded_lonlat = sh(lonlat)  # Get the embedding from Spherical Harmonics\n",
    "    # Append the resulting embedding to the list\n",
    "    embeddings_for_variable.append(embedded_lonlat.squeeze(0))  # Remove the extra dimension\n",
    "# Convert the list of embeddings into a 2D tensor for this variable\n",
    "embeddings_tensor = torch.stack(embeddings_for_variable)  # Shape: [num_stations, embedding_dim]\n",
    "\n",
    "# Save the embeddings for this variable to a file\n",
    "embeddings_file = Path('/data/zzn/insitu/nips') / f'{refinement_level}_healpix_embeddings_level_{level}.pt'\n",
    "torch.save(embeddings_tensor, embeddings_file)\n",
    "print(f\"Embeddings for {refinement_level} saved to {embeddings_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12288, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
